{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KDQ4GTf9pAB"
   },
   "source": [
    "# Ejercicio Industria 4.0\n",
    "\n",
    "En este ejercicio se intentará obtener unos resultados a partir de un dataset muy famoso de clasificación de música de spotify. Todos los imports necesarios ya estan añadidos en el siguiente código.\n",
    "\n",
    "### Todos los campos a modificar se identificaran por el simbolo @.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Leer el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(@)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Revisar los campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Eliminar filas no utiles + filas con nulos\n",
    "\n",
    "Para ello, hay que revisar que puede significar cada fila y identificar aquellas que no nos sirvan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasNoUtiles = [@, ...]\n",
    "dataset = dataset.drop(columns=columnasNoUtiles, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigando el dataset nos hemos dado cuenta que aparecen simbolos \"?\" para codificar algunos missings.\n",
    "\n",
    "Elimina todas las filas que tengan este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()\n",
    "dataset = dataset[~dataset.apply(lambda row: @ in row.values, axis=1)]\n",
    "# Coger el numero de clases\n",
    "nClases = len(dataset.music_genre.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Transformar columnas categoricas en numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasCategoricas = [@, ...]\n",
    "dataset = pd.get_dummies(dataset, columns=columnasCategoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar que efectivamente la conversión ha funcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Extraer la columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetCol = @\n",
    "\n",
    "Y = dataset[targetCol]\n",
    "X = dataset.drop([targetCol],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Particionar entre train i test\n",
    "\n",
    "Haz una partición entre train i test manteniendo solamente el 25% de los datos en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(@, @, test_size=@, shuffle=True, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba los tamaños de las particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test), len(Y_train), len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Seleccionar y probar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM's\n",
    "\n",
    "Probar los kernels 'linear' y 'rbf'. Este último es más lento. Entrena el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = SVC(kernel=@)\n",
    "knc.fit(@, @)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predice con los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knc.predict(@)\n",
    "print(sklearn.metrics.confusion_matrix(Y_test,pred))\n",
    "print(sklearn.metrics.accuracy_score(Y_test,pred))\n",
    "print(sklearn.metrics.classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "Prueba con 100 y 500 estimadores. Entrena el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = @)\n",
    "rf.fit(@, @)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predice con los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(@)\n",
    "print(sklearn.metrics.confusion_matrix(Y_test,pred))\n",
    "print(sklearn.metrics.accuracy_score(Y_test,pred))\n",
    "print(sklearn.metrics.classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales\n",
    "\n",
    "Primero de todo hay que convertir la salida con One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(pd.DataFrame(Y_train))\n",
    "Y_test = pd.get_dummies(pd.DataFrame(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una red neuronal con 2 capas internas. La primera de ellas con 128 neuronas y la segunda con 64. Recuerda terminar con una capa con el numero de clases a clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3328      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,234\n",
      "Trainable params: 12,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(@, input_shape=(len(X.columns), ), activation='linear'))\n",
    "model.add(Dense(@, activation='linear'))\n",
    "model.add(Dense(@, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena durante 15 epocas con una partición de validación de 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = @\n",
    "validation_split = @\n",
    "history = model.fit(@, @, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parece que functiona muy mal. A que se debe esto?\n",
    "Las capas no tienen activación == activación linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repite la red pero prueba a cambiar las functiones de activation de la red para que sean dos relu al principio y una softmax al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(@, input_shape=(len(X.columns), ), activation=@))\n",
    "model.add(Dense(@, activation=@))\n",
    "model.add(Dense(@, activation=@))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena durante 50 epocas con una partición de validación de 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = @\n",
    "validation_split = @\n",
    "history = model.fit(@, @, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enseña las curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['loss'], label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['accuracy'], label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo\n",
    "\n",
    "### Porque se realizan los argmax en la predicción y en la target de partición de test? @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "### Argmax's ###\n",
    "pred = np.argmax(pred, axis=1)\n",
    "y_test = np.argmax(Y_test.values, axis=1)\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(y_test,pred))\n",
    "print(sklearn.metrics.accuracy_score(y_test,pred))\n",
    "print(sklearn.metrics.classification_report(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1 - Deep Learning - Regressor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
